<!DOCTYPE html>
<html lang="en">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Flume+Kafka+Flink+Redis构建大数据实时处理系统（单机环境）--环境篇"/>




  <meta name="keywords" content="flume,flink,kafka, Eric's blog" />










  <link rel="alternate" href="/atom.xml" title="Eric's blog">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.6.0" />



<link rel="canonical" href="http://blog.eric7.site/2019/08/15/Flume-Kafka-Flink-Redis构建大数据实时处理系统（单机环境）-环境篇/"/>


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.6.0" />






  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>









    <title> Flume+Kafka+Flink+Redis构建大数据实时处理系统（单机环境）--环境篇 - Eric's blog </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Eric's blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            Home
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            Archives
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            About
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Eric's blog</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              Home
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              Archives
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              About
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Flume+Kafka+Flink+Redis构建大数据实时处理系统（单机环境）--环境篇
        
      </h1>
      <div class="post-meta">
        <span class="post-time">
          2019-08-15 16:23
        </span>
        
        
        
          <span class="post-updated">
          &nbsp; | &nbsp; 更新于
          <time itemprop="dateUpdated" datetime="2019-08-16T11:30:19+08:00" content="2019-08-16">
          2019-08-16
          </time>
          </span>
       
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-安装java环境"><span class="toc-text">1.安装java环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-安装scala"><span class="toc-text">2.安装scala</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-安装zookeeper"><span class="toc-text">3.安装zookeeper</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-安装kafka"><span class="toc-text">4.安装kafka</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-flume安装"><span class="toc-text">5.flume安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-flink安装"><span class="toc-text"> 6.flink安装 </span></a></li></ol>
    </div>
  </div>

    <div class="post-content">
      
        <p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1565806172964&amp;di=fcca31256b007193f7eab4ab980bc407&amp;imgtype=0&amp;src=http%3A%2F%2Fwww.variflight.com%2F_newstatic%2Fdest%2Fimg%2Fenglish%2Findex%2Fvideo_bg.jpg" alt="Photo"></p>
<p><strong>大体流程：</strong></p>
<ul>
<li><p>python readlog 读取本地日志文件发送到flume(本测试基于原有项目，原有项目是有scribe接收日志存到本地。正式项目flume直接读取本地文件 source改为直接监控日志文件 a1.sources.r1.type = exec, a1.sources.r1.command = tail -F /var/log/secure)</p>
</li>
<li><p>flume sink 数据到kafka</p>
</li>
<li><p>flink  scala消费kafka</p>
</li>
<li><p>存入到redis</p>
</li>
<li><p>django展示</p>
</li>
</ul>
<a id="more"></a>
<blockquote>
<p>这里原应有一个流程图，但是不知道为何markdown不支持flow流程图</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[scribe] --&gt; B[disk] </span><br><span class="line">A --&gt; C(hdfs)</span><br><span class="line">B --&gt; D[python ThriftFlumeEvent发送到flume]</span><br><span class="line">D --&gt; F[Flume]</span><br><span class="line">F --sink--&gt; G[kafka]</span><br><span class="line">G--scala--&gt; H[flink]</span><br></pre></td></tr></table></figure>
<p><strong>本机系统：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ubuntu 16.04</span><br><span class="line">conda环境下的python 3.7</span><br></pre></td></tr></table></figure>
<p><strong>需要安装的环境：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdk1.8.0_202，scala 2.11.6 ，zookeeper-3.4.5，kafka_2.11-2.3.0，flume-1.8.0，flink-1.8.0</span><br></pre></td></tr></table></figure>
<h2 id="1-安装java环境"><a href="#1-安装java环境" class="headerlink" title="1.安装java环境"></a><a name="fenced-code-block">1.安装java环境</a></h2><ul>
<li>这里安装1.8</li>
</ul>
<blockquote>
<p>环境存放到 cd /opt/</p>
</blockquote>
<ul>
<li><p>下载 wget <a href="https://repo.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz" target="_blank" rel="noopener">https://repo.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz</a></p>
<p>(这里是用华为的镜像地址下载，oracle需要登陆账号)</p>
</li>
<li><p>解压到指定目录 tar -zxvf jdk-8u202-linux-x64.tar.gz</p>
</li>
<li><p>vim ~/.bashrc  添加环境变量如下</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/jdk1.8.0_202  ## 这里要注意目录要换成自己解压的jdk 目录</span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib</span><br><span class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>立即生效<br>source ~/.bashr</p>
<p>验证 java -version</p>
<h2 id="2-安装scala"><a href="#2-安装scala" class="headerlink" title="2.安装scala"></a><a name="fenced-code-block">2.安装scala</a></h2><ul>
<li><p>这里安装2.11版本</p>
</li>
<li><p>spark和scala版本对应关系: spark1.6.2–scala2.10 spark2.0.0–scala2.11<br>本机还要安装spark2.0所以这里安装的是2.11.6</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://downloads.lightbend.com/scala/2.11.6/scala-2.11.6.tgz</span><br><span class="line"></span><br><span class="line">tar -zxvf scala-2.11.6.tgz -C /opt/scala-2.11.6</span><br><span class="line"></span><br><span class="line">vim ~/.bashrc</span><br><span class="line"></span><br><span class="line">source ~/.bashrc</span><br><span class="line"></span><br><span class="line">添加环境变量如下</span><br><span class="line">export SCALA_HOME=/opt/scala-2.11.6</span><br><span class="line">export PATH=$PATH:$&#123;SCALA_HOME&#125;/bin</span><br><span class="line"></span><br><span class="line">验证 scala -version</span><br></pre></td></tr></table></figure>
<h2 id="3-安装zookeeper"><a href="#3-安装zookeeper" class="headerlink" title="3.安装zookeeper"></a><a name="fenced-code-block">3.安装zookeeper</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">下载 wget http://archive.apache.org/dist/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz</span><br><span class="line"></span><br><span class="line">解压 tar -zxvf zookeeper-3.4.5.tar.gz -C /opt/zookeeper-3.4.5</span><br><span class="line"></span><br><span class="line">进入解压目录  cd /opt/zookeeper-3.4.5/conf/</span><br></pre></td></tr></table></figure>
<ul>
<li><p>拷贝配置文件 cp zoo_sample.cfg  zoo.cfg</p>
</li>
<li><p>vim zoo.cfg 添加如下内容</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">修改zookeeper数据存放地址，dataDir,dataLogDir</span><br><span class="line"></span><br><span class="line">dataDir=/data/zookeeper/data</span><br><span class="line">dataLogDir=/data/zookeeper/log</span><br></pre></td></tr></table></figure>
<ul>
<li>新建添加的zk数据目录</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/zookeeper/data</span><br><span class="line">mkdir /data/zookeeper/log</span><br><span class="line">在/data/zookeeper/data 目录新建一个myid文件，内容为1，代表服务器的编号是1</span><br></pre></td></tr></table></figure>
<ul>
<li>vim /etc/profile    添加环境变量</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper-3.4.5</span><br><span class="line">export PATH=.:$ZOOKEEPER_HOME/bin:$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<ul>
<li><p>source /etc/profile 立即生效</p>
</li>
<li><p>进入zk解压目录 <code>cd /opt/zookeeper-3.4.5</code></p>
</li>
<li><p>启动  <code>bin/zkServer.sh  start</code>  此命令会在当前目录创建日志文件</p>
</li>
</ul>
<blockquote>
<p>输出以下代表已启动正常，如有错误查看当前目录日志 zookeeper.out</p>
</blockquote>
<blockquote>
<p>JMX enabled by default<br>Using config: /opt/zookeeper-3.4.5/bin/../conf/zoo.cfg<br>Starting zookeeper … STARTED</p>
</blockquote>
<p>查看启动状态：</p>
<ul>
<li><code>bin/zkServer.sh status</code></li>
</ul>
<p>输出：</p>
<blockquote>
<p>JMX enabled by default<br>Using config: /opt/zookeeper-3.4.5/bin/../conf/zoo.cfg<br>Mode: standalone</p>
</blockquote>
<h2 id="4-安装kafka"><a href="#4-安装kafka" class="headerlink" title="4.安装kafka"></a><a name="fenced-code-block">4.安装kafka</a></h2><p><img src="https://kafka.apache.org/images/kafka_diagram.png" alt="kafka"></p>
<ul>
<li><p>这里安装 2.3.0 </p>
</li>
<li><p>kafka_2.11-2.3.0  2.11为scala版本，kafka版本为2.3.0</p>
</li>
<li><p>下载 <code>wget https://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.0/kafka_2.11-2.3.0.tgz</code></p>
</li>
<li><p>解压 <code>tar -zxvf kafka_2.11-2.3.0.tgz -C /opt/kafka_2.11-2.3.0</code></p>
</li>
<li><p>添加环境变量</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line"></span><br><span class="line">export KAFKA_HOME=/opt/kafka_2.11-2.3.0</span><br><span class="line"></span><br><span class="line">export PATH=$KAFKA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>立即生效 <code>source ~/.bash_profile</code></p>
<ul>
<li><p>kafka需要使用Zookeeper,所以需要启动Zookeeper服务,上面的操作就已经启动了Zookeeper服务<br>如果没有的话,可以使用kafka自带的脚本启动一个简单的单一节点Zookeeper实例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/kafka_2.11-2.3.0/</span><br><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</span><br></pre></td></tr></table></figure>
</li>
<li><p>现在启动kafka(前台执行，会打印日志)  <code>bin/kafka-server-start.sh config/server.properties</code></p>
</li>
</ul>
<p>后台执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//配置了环境变量,1代表标准输出,2代表错误输出,把2重定向到标准输出1需要使用&amp;,最后的&amp;表示后台运行</span><br><span class="line">nohup bin/kafka-server-start.sh config/server.properties &gt; kafka_start.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>创建一个主题,只使用单个分区一个复本<br><code>bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code></p>
</li>
<li><p>启动生产者发送消息</p>
</li>
</ul>
<p><code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</code></p>
<blockquote>
<p>Hello Kafka</p>
</blockquote>
<p>另开终端启动消费者进行消费信息</p>
<p><code>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test</code></p>
<p>消费者成功打印出</p>
<blockquote>
<p>Hello Kafka</p>
</blockquote>
<p>kafka相关命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//启动kafka</span><br><span class="line">bin/kafka-server-start.sh config/server.properties </span><br><span class="line">//停止kafka</span><br><span class="line">bin/kafka-server-stop.sh</span><br><span class="line">//创建topic,--replication-factor指定副本个数,--partitions指定分区个数</span><br><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</span><br><span class="line">//查看所有的topic信息</span><br><span class="line">bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br><span class="line">//启动生产者</span><br><span class="line">bin/kafka-console-producer.sh --broker-list your.host.name:9092 --topic test</span><br><span class="line">//启动消费者</span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server your.host.name:9092 --topic test --from-beginning</span><br><span class="line">//删除topic</span><br><span class="line">bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic test</span><br></pre></td></tr></table></figure></p>
<p>如果后期开发的话需要对kafka配置进行修改 server.properties</p>
<p>其他参数没有深究，其他配置可以参考官网说明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//用于区分broker,必须唯一</span><br><span class="line">broker.id=0</span><br><span class="line"></span><br><span class="line">//代理将向生产者和消费者宣传的主机名和端口。 如果没有设定，它将使用“listeners”的值。否则，它从java.net.InetAddress.getCanonicalHostName获得。</span><br><span class="line">advertised.listeners=PLAINTEXT://外网ip:9092</span><br><span class="line"></span><br><span class="line">//配置zookeeper的地址,zookeeper集群地址以逗号隔开</span><br><span class="line">zookeeper.connect=localhost:2181</span><br><span class="line"></span><br><span class="line">//配置数据存放目录</span><br><span class="line">log.dirs=/data/kafka2.3</span><br></pre></td></tr></table></figure>
<p>advertised.listeners是个坑，这里说明下，也是让自己长点记性</p>
<p>官方解释：</p>
<blockquote>
<p>Listeners to publish to ZooKeeper for clients to use, if different than the listeners above.<br>In IaaS environments, this may need to be different from the interface to which the broker binds.<br>If this is not set, the value for listeners will be used.</p>
</blockquote>
<p>下面是默认配置，没有修改：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#listeners=PLAINTEXT://:9092</span><br><span class="line">#advertised.listeners=PLAINTEXT://your.host.name:9092</span><br><span class="line">zookeeper.connect=localhost:2181</span><br></pre></td></tr></table></figure></p>
<p>注释的两个参数，虽然注释了，但是通过介绍可以知道，这两个参数，可以通过java.net.InetAddress.getCanonicalHostName获得，也就是可以获取到127.0.0.1  这样的话，本机测试是可以正常消费和生产数据的，但外网不行。</p>
<p>经各种测试后发现，修改kafka的advertised.listeners 为外网ip 即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#listeners=PLAINTEXT://:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://外网ip:9092</span><br><span class="line">zookeeper.connect=localhost:2181</span><br></pre></td></tr></table></figure></p>
<h2 id="5-flume安装"><a href="#5-flume安装" class="headerlink" title="5.flume安装"></a><a name="fenced-code-block">5.flume安装</a></h2><ul>
<li>Flume<br><img src="https://flume.apache.org/_images/DevGuide_image00.png" alt="photo"></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://archive.apache.org/dist/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz</span><br><span class="line">tar -zxvf apache-flume-1.8.0-bin.tar.gz</span><br><span class="line">重命名 mv apache-flume-1.8.0-bin flume-1.8.0</span><br></pre></td></tr></table></figure>
<p>添加环境变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line">export FLUME_HOME=/opt/flume-1.8.0</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br></pre></td></tr></table></figure></p>
<p>立即生效 <code>source ~/.bash_profile</code></p>
<p>进入解压目录修改配置<code>cd /opt/flume-1.8.0/conf/</code><br><code>mv flume-env.sh.template flume-env.sh</code></p>
<p><code>vim flume-env.sh</code> 去掉注释，配置正确的java路径<br><code>export JAVA_HOME=/opt/jdk1.8.0_202</code></p>
<p>验证 <code>flume-ng version</code> 输出：</p>
<blockquote>
<p>Flume 1.8.0<br>Source code repository: <a href="https://git-wip-us.apache.org/repos/asf/flume.git" target="_blank" rel="noopener">https://git-wip-us.apache.org/repos/asf/flume.git</a><br>Revision: 99f591994468633fc6f8701c5fc53e0214b6da4f<br>Compiled by denes on Fri Sep 15 14:58:00 CEST 2017<br>From source with checksum fbb44c8c8fb63a49be0a59e27316833d</p>
</blockquote>
<p>拷贝并修改配置<code>cp flume-conf.properties.template   flume-conf.properties</code></p>
<p>使用官方配置,官方配置使用netcat源，更多源查看官方网站<a href="[https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#spooling-directory-source](https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#spooling-directory-source">https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#spooling-directory-source</a>)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#example.conf: A single-node Flume configuration</span><br><span class="line"></span><br><span class="line">#Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line">#Describe/configure the source</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line">#Describe the sink</span><br><span class="line">#打印内容到日志中</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line">#Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line">#Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p>启动验证<br><code>bin/flume-ng agent --conf conf --conf-file conf/flume-conf.properties --name a1 -Dflume.root.logger=INFO,console</code></p>
<p>另起窗口输入,然后输入内容，前面的终端会输出内容，测试成功。</p>
<blockquote>
<p>telnet localhost 44444</p>
</blockquote>
<ul>
<li>这里要使用,Thrift源。因为项目中原本要兼容flume+scribe，新建配置 flume-thrift.properties,接收python发送过来的日志</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">tier1.sources  = source1</span><br><span class="line">tier1.channels = channel1</span><br><span class="line">tier1.sinks    = sink1</span><br><span class="line"></span><br><span class="line">tier1.sources.source1.channels = channel1</span><br><span class="line">tier1.channels.channel1.type   = memory</span><br><span class="line">tier1.sources.source1.type = thrift</span><br><span class="line">tier1.sources.source1.bind = 0.0.0.0</span><br><span class="line">tier1.sources.source1.port = 4444</span><br><span class="line"></span><br><span class="line">tier1.sources.source1.selector.type = multiplexing</span><br><span class="line">tier1.sources.source1.selector.header = GAMENAME</span><br><span class="line">tier1.sources.source1.selector.mapping.FSZHS = channel1</span><br><span class="line"></span><br><span class="line">#配置sink下沉到kafka，kafka来消费数据</span><br><span class="line">tier1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">tier1.sinks.sink1.brokerList = localhost:9092</span><br><span class="line">tier1.sinks.sink1.topic = test</span><br><span class="line">tier1.sinks.sink1.serializer.class = kafka.serializer.StringEncoder</span><br><span class="line">tier1.sinks.sink1.channel = channel1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tier1.channels.channel1.capacity = 5000</span><br><span class="line">tier1.channels.channel1.transactionCapacity = 2000</span><br><span class="line"></span><br><span class="line">#日志中打印出内容</span><br><span class="line">#tier1.sinks.sink1.type = logger</span><br><span class="line">#tier1.sinks.sink1.channel = channel1</span><br></pre></td></tr></table></figure>
<p>关于selector参数的说明： </p>
<p>它的type 有<strong> Multiplexing </strong>,<strong> Replicating</strong> , 这里是用selector来根据header的GAMENAME内容分发到对应的channel，暂时不做存储。（项目需要本地，hdfs分别一份，每个项目需要两个channel）</p>
<p>区别是：Replicating 会将source过来的events发往所有channel,而Multiplexing 可以选择该发往哪些channel</p>
<p>之前没有设置会出现<code>Thrift source %s could not append events to the channel.</code></p>
<p>查阅资料,这和memory channel的另一个参数有关：</p>
<p>transactionCapacity，（The maximum number of events the channel will take from a source or give to a sink per transaction）表明source给channel、channel给sink一次发送的event个数，如果不设置，默认值为100。所以当我设置batchsize为100时，可以正确发送，但是超过100，就发送失败。</p>
<p>关于参数<strong> transactionCapacity </strong> 和<strong> capacity </strong> :</p>
<blockquote>
<p>a1.sinks.k1.hdfs.batchSize 官方解释:</p>
<p>##number of events written to file before it is flushed to HDFS<br>a1.channels.c1.capacity  官方解释 :  </p>
<p>#The maximum number of events stored in the channel<br>a1.channels.c1.transactionCapacity 官方解释 :   </p>
<p>#The maximum number of events the channel will take from a source or give to a sink per transaction</p>
</blockquote>
<p>这三者之间的关系:</p>
<p>batchsize &lt;=transactionCapacity&lt;=capacity</p>
<h2 id="6-flink安装"><a href="#6-flink安装" class="headerlink" title=" 6.flink安装 "></a><a name="fenced-code-block"> 6.flink安装 </a></h2><p><img src="https://flink.apache.org/img/flink-home-graphic.png" alt="flink"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://archive.apache.org/dist/flink/flink-1.8.0/flink-1.8.0-bin-scala_2.11.tgz</span><br><span class="line"></span><br><span class="line">解压 tar -zxvf apache-flume-1.8.0-bin.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>启动flink <code>bin/start-cluster.sh</code></p>
<p>查看web <a href="http://localhost:8081" target="_blank" rel="noopener">http://localhost:8081</a></p>
<ul>
<li>测试   nc -l 9000 输入<blockquote>
<p>hello flink </p>
</blockquote>
</li>
</ul>
<p>启动官方demo<br><code>./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000</code></p>
<p>查看日志log目录下</p>
<p><code>tail -f flink-root-taskexecutor-0-xxxxxxxxx.out</code></p>
<p>输出：</p>
<blockquote>
<p>(hello,1)<br>(flink,1)</p>
</blockquote>
<p>至此环境搭建完成。</p>

      
    </div>

    
      
      



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/flume-flink-kafka/">flume,flink,kafka</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2019/08/16/通过Thrift-source向Flume发送数据的Python实现/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">通过Thrift source向Flume发送数据的Python实现</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2019/05/10/今日更新-1/">
        <span class="next-text nav-default">今日更新</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zODE3OC8xNDcwNg">
        <noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
      </div>  
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:me@eric7.site" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://www.instagram.com/eric.liu__/" class="iconfont icon-instagram" title="instagram"></a>
        
      
    
    
    
  </div>


<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2018 - 
    
    2019

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Eric</span>
  </span>
  
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span>
  
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  
   <script type="text/javascript">
	(function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
  </script>




    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  


    <script type="text/javascript" src="/js/src/even.js?v=2.6.0"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.6.0"></script>

  </body>
</html>
